# Go 数据结构

### Channel

- **重要思想：CPS**
    - go有一个非常重要的设计思想：**不要通过共享内存的方式进行通信，而是应该通过通信的方式共享内存，**前者通过修改共享变量的标识，来使其他线程感知变化，实现通信；而go采用一个更高级的数据结构 Channel 用于协程间的通信
- **底层实现**：**环形缓冲区、发送和接收队列，锁**
    - 它的底层表示是一个   hchan  结构体，里面主要包含一个**环形队列**   ring buffer ，还有**发送和接收两条双向链表**   sendq  和   recvq  ，还有一个把互斥锁 lock 和一个状态标志   closed
    - **环形缓冲区**：首先是 **ring buffer**，用于缓存数据的一个**环形队列**，有队尾和队头两个索引分别记录下次存和取的位置，在定义 Channel 的时候可以指定大小，生成一个固定⻓度的环。为什么要使用环形呢？主要是可以重复利用空间，不用频繁的申请和销毁空间
        - **缓冲区的数据类型**可以是各种类型，除了传递数据，有时候也会使用空结构体作为 Channel 的数据类型，用于只发送信号而不携带具体的数据。这种用法常⻅于实现某种同步机制，例如用于多个 Goroutine 之间的信号通知或触发事件
        - **无缓冲区**的 Channel 为了确保数据交付的可靠性，必须让协程同步地通信，适合于两个协程直接通信；
        - **有缓冲区**的 Channel 为了提高通信速率，允许多个协程异步地通信，适合于解耦发送者和接收者的时间差异，提高并发性能
    - **发送和接收队列：**其次是 **sendq 和 recvq 两条双向链表**，作为**发送和接收队列**，在 sendq 和 recvq 中抽象了链表的头和尾节点。队列存的是对goroutine的封装 sudog 结构体，除了有当前协程的表示，还有前驱和后继的协程。这两条链表主要是用来休眠等待发送和接收的协程列表
    - **锁**：其实它也是带**锁**的结构，那它为什么还支持高效的并发呢？因为它的锁仅在发送和接收数据时使用，对锁的使用时机很少，所以也能支持高效的并发。
    - **closed状态**：最后 **closed** 就没什么介绍的了，值为 1 表示关闭，0 表示未关闭。但是要注意，如果往关闭的 Channel 里面发送数据会引起panic；从关闭的 Channel 里接收数据会得到剩余的数据或者对应类型的零值。对于值为 nil的 Channel，发送和接收数据都会造成永久堵塞
- **发送数据**：**先看有没有人在等这个数据**
    - 首先，判断是否有阻塞的**读协程**（意味着缓冲区是空的），有的话直接把要写的数据给读协程，并唤醒它
    - 其次，判断**缓冲区**满不满，不满正常写入尾部，满了，则挂起，加入写协程的阻塞队列
- **接收数据**：
    - 首先，判断是否有阻塞的**写协程**（意味着缓冲区满了），此时读取缓冲区的首元素（缓冲区有空位了），并且将阻塞队列的第一个写协程数据复制给缓冲区，最后唤醒该写协程
    - 其次判断，**缓冲区**是否为空，不为空，读取即可，为空，则加入读协程的阻塞队列
- **关闭channel:**
    - 关闭未初始化的channel会panic
    - 重复关闭channel 会panic
    - 关闭时会唤醒该channel的阻塞队列中的所有读/写协程(不可能同时有阻塞的读和写协程)，因为该channel要关闭了，无法继续服务了
        
        （先遍历阻塞队列加入glist，然后遍历glist统一goreaady唤醒，读协程返回零值，写协程唤醒完会panic(因为是channel关闭所导致的唤醒，即是写失败的)）
        
- **channel异常情况**：
    - **发生 panic 的三种情**
    1. 向一个关闭的 channel 进行写操作；
    2. 关闭一个 nil 的 channel；
    3. 重复关闭一个 channel。
    - **发生阻塞的三种情况**
    1. 读一个 nil channel 都会被阻塞。
    2. 写一个 nil channel 都会被阻塞。
    3. 读写缓冲为空或者已经满了且没有挂起的接收者和发送者。
- **channel使用注意**：
    - 在合适的时机关闭 Channel，以释放资源并防止内存泄漏
    - 避免在多个协程中重复关闭同一个 Channel，以避免引发 panic
    - 尽量在发送数据的协程 关闭 Channel，避免发送方在 Channel 被外部关闭后尝试发送数据导致panic
    - 避免将 Channel 设置为 nil，以避免因对 nil Channel 的收发操作造成死锁

### Slice

- **为什么要有切片**？
    - 首先数组**长度不可变**，初始化必须指定长度，然而，在许多情况下，我们并不知道需要多大的内存空间，希望能够在使用过程中动态地扩容
    - 其次数组是**值类型**，赋值或传递时会进行拷⻉，对大数组来说，拷⻉的开销很大
    - 所以因为这样两个原因，我们需要一个引用类型的、支持动态添加元素的新「数组」类型，这就是切片；
    - 切片是基于数组实现的，底层是数组，可以理解为对底层数组的抽象
- **切片的底层实现**？
    - 切片的底层表示非常简单，只有三个字段：指向**底层数组的指针**（array）、**切片的⻓度**（len）、**切片的容量**（cap）。⻓度表示当前存储的元素数量，容量表示可以容纳的总元素数量，但不一定等于底层数组的容量，它们的关系是   len <= cap 。为什么要用指针表示底层数组呢？一方面是为了能够处理所有类型的数据，另一方面是为了方便扩容和实现类似引用传递的效果。因此，对底层数组的引用是一个   unsafe.Pointer  指针类型
    - **创建**：
        - 在 Go 语言中，可以使用字面量和   make()  函数两种方式创建切片。使用字面量从数组或旧切片中切分出一个新切片时，初始阶段会共享底层数组，不熟悉底层可能会导致隐藏的 bug。因此，推荐使用   make()  函数或直接使用字面量的方式来创建切片
    - **添加**：
        - **索引赋值**：添加元素通常有两种方式。一种类似于数组，直接使用索引赋值，但要确保索引范围在   [0, len)内，否则会发生越界 panic，这种方式不会触发扩容，本质上是修改底层数组对应索引的值
        - **append追加**：这会在切片底层数组的末尾添加一个或多个元素，可能导致容量不足而**触发扩容**
- **扩容机制**：
    - **大致思路**：当需要扩容时，申请一块更大的内存数组，将旧底层数组的值逐个拷⻉到新数组中，然后切片切换到新的底层数组的引用。具体要申请多大的内存取决于不同版本的策略
    - 关于切片的扩容机制，一开始我在网上看到的很多资料都说，**在元素数量小于 1024 时，切片的容量会成倍增⻓，而在 1024 之后，容量增⻓为旧容量的 1.25 倍**。然而，当我自己进行测试时发现与这个规则不同。经过进一步验证，我得出的结论是：**切片的扩容机制涉及一个扩容因子，它以旧容量乘以扩容因子的方式来确定新的容量。具体而言，在元素数量小于等于 256 时，可以认为扩容因子是 2，但在 256 之后，扩容因子会逐步递减为 1.6 几、1.4 几，最终无限趋近于 1.25**。后来我查阅了相关资料，发现后一种扩容规则是在 Go 语言版本 1.18 之后引入的，之前的版本采用的是第一种扩容规则
    - 1.18之前：**如果原容量是1000， 按照双倍扩容就是2000。如果容量是1024，按照1.25被扩容就是1280。这里在1024临界处，原容量大的扩容后反而小，不是一个单调递增的趋势，发生突变。**
    - 1.18之后：优化了切片扩容的策略，让底层数组大小的增长更加平滑： 通过减小阈值并固定增加一个常数，使得优化后的扩容的系数在阈值前后不再会出现从2到1.25的突变，而是逐步减少趋近1.25
    - 由于扩容大概率需要重新分配内存，并将旧数组的元素逐个拷⻉到新数组中，因此扩容会带来较大的开销。**`无论是哪种扩容规则，当元素数量较少时，为了减少频繁的扩容，切片会采用成倍增⻓的方式。而当达到一定阈值后，由于元素拷⻉和新内存的开销变得非常显著，扩容倍数会减少至 1.25。新版本的扩容机制更加平滑地过渡，以更好地平衡性能和内存开销的考量`**
    - 注意：如果切片是通过数组或旧切片切分出来，并且需要扩容的大小小于被切分数组或旧切片的容量，切片的扩容不会申请新的数组，而是继续使用旧底层数组的内存
- **slice不是线程安全的：**
    - **线程安全**：多线程同时对一个对象进行并发读写，调用这个对象的行为都可以获得正确的结果 若有多个线程同时执行写操作，一般都需要考虑线程同步，否则的话就可能影响线程安全
    - slice底层没有使用加锁等方式，不支持并发读写，在并发读写时不会报错，但是会数据丢失

### Map

- Map 是 Go 语言中常用的数据结构，是采用拉链法实现的哈希表，底层是一个**hmap**结构体，包含一个桶数组**buckets**，数组的每个哈希桶是一个单向链表，以**桶bmap**为节点进行串联
- **使用流程**：
    - **写保护检测**：函数首先会检查map的标志位flags。如果flags的写标志位此时被置1了，说明有其他协程在执行‘写’操 作，进而导致程序panic，这也说明了**map不是线程安全**的
        - **为什么map不是线程安全的呢？**这是因为map的内部实现涉及一系列复杂的操作，比如渐进驱逐式扩容，这些操作需要保证原子性和一致性。如果在没有锁机制的情况下，多个Goroutine并发执行这些操作，可能会破坏map的内部结构，导致严重的错误
    - **计算hash值**：首先通过哈希方法取得 key 的 hash 值；
    - **bucket桶定位**：然后将hash 值对桶数组长度取模（& 桶数组长度-1，即看hash值的后B位），确定其所属的桶；
    - **查找**：在桶中先查找比对key是否存在，首先比对tophash（key的hash值的高8位）快速定位key，找到相同的高八位后，还需要比较该索引位置的键是否与查找的键相等，都遍历完后，查看此桶是否有挂载溢出桶，如果有，则重复上述操作，直到找到目标key；在扩容状态下，可能需要在旧桶中查找数据
    - 插入：和查找一样，如果找到就覆盖，如果没找到就找空位插入，倘若桶的 8 个位置都已被占满，则基于桶的溢出桶指针，找到下一个桶，倘若遍历到链表尾部，仍未找到空位，则基于拉链法，在桶链表尾部续接新桶，并插入 key-value 对
- **桶数组buckets**：桶数组长度为2的整数次幂，每个**bmap桶**固定可以存放 **8 个** key-value 对以及其tophash值；倘若超过 8 个 key-value 对打到桶数组的同一个索引当中，此时会通过创建桶链表的方式来化解这一问题.
    - 注意：
        - bmap包含3个大小为8的数组，分别存放tophash,key,value;以及还有一个溢出桶指针，指向链表的下一个桶
        - **bmap桶内存储key 和value是分开放的**，并不是 key/value/key/valuer …这样的形式，当key和alue类型不一样的时候，key和value占用字节大小不一样，使用keylvalue这种形式可能会因为内存对齐导致内存空间浪费，所以Go采用key和value分开存储的设计，更节省内存空间
- **扩容机制**：
    - 负载因子：元素数量 / 桶的数量
    - **增量扩容**：数据增长，效率较低
        - **触发条件**：负载因子大于 6.5时，说明元素数量太多，而桶的数量太少，查找一个键可能会花费很⻓时间，因此，扩容的思路是增加桶的数量，也就是将 B 加1，桶的数量翻倍
        - **扩容流程**：新建一个buckets数组，新的buckets大小是原来的2倍，并且将 Buckets 桶数组的指针指向新数组，将 oldBuckets 指针指向旧数组，然后旧的buckets数据 搬迁到新的buckets；
        - 注意：
            - 在增量扩容流程中，新桶数组的长度会扩展一位，假定 key 原本从属的桶号为 i，则在新桶数组中从属的桶号只可能是 i （x 区域）或者 i + 老桶数组长度（y 区域）
            - 扩容后，桶数翻倍，取余（&）操作会多看左边一位，原有桶的数据依据该位上的0/1指示是在新桶的原下标，还是原下标+旧桶的长度
    - **等量扩容**：数据稀疏，内存泄漏
        - **触发条件**：在负载因子比较小的情况下（map里元素总数少，但是桶数量多），有可能map的查找和插入效率也很低，比如不断的增删，这样会造成overflow的bucket数量增多，但负载因子又不高，就不能触发扩容来缓解这种情况。这样会造成桶的使用率不高，值存储得比较稀疏，查找插入效率会变得非常低，因此有了等量扩容，当桶内溢出桶数量大于等于 2^B 时( B 为桶数组长度的指数，B 最大取 15)，发生等量扩容，桶的长度保持为原值；
        - **扩容流程**：buckets数量维持不变，但是重新做一遍类似双倍扩容的搬迁操作， 把松散的键值对重新排列一次，使得同一个bucket中的key排列地更紧密，节省空间，提高buckets利用 率，进而保证更快的存取
    - **渐进式策略**：
        - 当桶被实际操作到时，由使用者负责完成数据迁移，避免因为一次性的全量数据迁移引发性能抖动，具体来说，由每次**写操作**实现命中桶的迁移，以及下一个需要迁移的数据，来逐步推进扩容
        - 在扩容期间，**读操作**会优先访问旧的桶数组
    
- **map遍历是无序的**
    - map在扩容后，会发生key的搬迁，这造成原来落在一个buket中的Key搬迁后，有可能会落到其他bucket中了，从这个角度看，遍历map的结果就不可能是按照原来的顺序了
    - 使用range多次遍历map时输出的key和vabue 的顺序可能不同。这是Go语言的设计者们有意为之（**不从固定的0号bucket开始遍历的，而从一个随机值序号的bucket， 再从其中随机的cell开始遍历**），旨在提示开发者们，Go底层实现并不保证map遍历顺序稳定（扩容时），请大家不要依赖range遍历结果顺序

### Sync.Map

- 解决 map 并发读写的问题，保证并发场景下的数据一致
- 常规思路：map + 锁 ：map作为临界资源，被锁保护，通过获取锁将一系列并发操作，退化成串行，规避了并发读写的风险
- **sync.Map做法：以空间换时间、冗余一个只读map，即两个map（read map 和 dirty map）一个读（无锁，包括读，更新，删除），一个写（加锁、插入写），大大减少加锁频率**
    - 首先基于无锁操作访问 read map；倘若 read map 不存在该 key，则加锁并使用 dirty map 兜底；并且希望能多用 read map，少用 dirty map，因为操作前者无锁，后者需要加锁；
    - 所以dirty map数据始终比read map新
    - 当不命中率misses达到一定阈值时，会发生read map 和 dirty map 之间会交替轮换更新
    - **倘若写操作过多，sync.Map 基本等价于互斥锁 + map**，所以sync.Map适用于读多写少的场景，因此，在选择使用sync.Map还是锁+map时，需要根据具体的使用需求进行权衡和选择
    
- 额外补充：
    - sync.Map的readmap没有加锁，而是通过for循环+原子操作的方式来保证并发修改安全。锁是保证同一时刻只有一个goroutine访问临界资源, for+原子操作是保证最后总有一个goroutine完成最后的修改，但是至于谁是最后一个，这是gmp模型进行调度的。
    - 总而言之，无论是锁还是for循环+原子操作，都保证了goroutine对临界资源的修改具有先后顺序(但至于谁先谁后是gmp调度决定的),而不是同时(同时会产生并发问题), 而如果大家有需求需要指定A先访问临界区，B再访问临界区，这就是goroutine同步的内容了, 可以了解下sync.waitgroup

### **Context**

为什么？(多goroutine 间数据传递，以及对 goroutine 的生命周期控制)

怎么实现？（4个方法，4个实现，一个额外取消接口，关闭只读channel）

- **为什么有Context**？
    - 我们知道Go 常用来写后台服务，通常只需要几行代码，就可以搭建一个 http server，Go 语言中的 server 实际上是一个“协程模型”，也就是说一个协程处理一个业务请求，每一个请求内部也会启动若干个 goroutine 同时工作，来提高响应速度
    - 那么如果在业务的高峰期，某个下游服务的响应变慢，而当前系统的请求又没有超时控制，或者超时时间设置地过大，那么等待下游服务返回数据的协程就会越来越多。而我们知道，协程是要消耗系统资源的，后果就是协程数激增，内存占用飙涨，严重甚至导致服务不可用，直接崩溃
    - 那么这时候通过设置“允许下游最长处理时间”就可以避免。如果超过这个时间还没有接收到返回数据，就直接向客户端返回一个默认值或者错误，并关闭这个请求的所有goroutine，系统就可以回收相关的资源
    - Context 包就是为了解决上面所说的这些问题而开发的：在 一组 goroutine 之间传递共享的值、取消信号、deadline等
    - 一句话：**context 用来解决 goroutine 之间`退出通知`、`元数据传递`的功能**，从而在异步场景中实现并发协调以及对 goroutine 的生命周期控制
- **Context底层实现原理**？4个方法，4个实现
    - **Context** 是一个**接口**，定义了 4 个核心方法：
        - **Deadline()**：返回当前 Context 的截止时间
        - **Done()**：返回一个通道（Channel），当这个 channel 被关闭时，说明 context 被取消了。注意，这是一个**只读**的channel。 我们又知道，读一个关闭的 channel 会读出相应类型的零值。并且源码里没有地方会向这个 channel 里面塞入值。换句话说，这是一个 `receive-only` 的 channel。因此在子协程里读这个 channel，除非被关闭，否则读不出来任何东西。也正是利用了这一点，子协程从 channel 里读出了值（零值）后，就可以做一些收尾工作，尽快退出
        - **Err()**：返回表示 channel 被关闭的原因。例如是被取消，还是超时
        - **Value()**：返回当前Context中存储对应键的值
    - **额外的canceler接口**
        - 封装了取消Context的cancel,Done两个方法，实现了该接口定义的两个方法的 Context，就表明该 Context 是可取消的`*cancelCtx` 和 `*timerCtx` 这两个Context类型就实现这个接口
        - 这样设计的原因：
            - “取消”操作应该是建议性，而非强制性，所以Context接口没有实现cancel方法
    - **4种Context类型实现**：
        - **emptyCtx**：初始化的空上下文，本质上类型为一个整型context.Background()和context.TODO()都是返回一个emptyCtx，context.Background()返回的context一般作为**根对象**存在，其不可以退出，也不能携带值。要具体地使用context的功能，需要派生出新的context；context.TODO()一般在不知道创建什么context对象的时候用
        - **cancelCtx：**结构体包括接口匿名字段，锁mu, done channel等字段，方法上**除了**实现Context接口之外，还实现了**canceler接口，**通过context.WithCancel()函数新创建一个可取消context并且有cancel退出方法。子context在两种情况下会退出，一种情况是调用cancel，另一种情况是当参数中的父context退出时，该context及其关联的context都退出
            - `cancel()` 方法的功能就是关闭 channel：c.done；然后递归地取消它的所有子节点；最后从父节点从删除自己。达到的效果是通过关闭 channel，将取消信号传递给了它的所有子节点。goroutine 接收到取消信号的方式就是 select 语句中的`读 c.done` 被选中
        - **timerCtx：**在 **cancelCtx** 基础上又做了一层封装，除了继承 cancelCtx 的能力之外，新增了一个 **time.Timer** 用于定时终止 context；另外新增了一个 **deadline** 字段用于字段 timerCtx 的过期时间. 通过`WithTimeout` 函数或者 `WithDeadline`函数创建，`WithDeadline` 需要用的是绝对时间，`WithTimeout` 调用了`WithDeadline`函数，传入的 deadline 是当前时间加上 timeout 的时间，也就是从现在开始再经过 timeout 时间就算超时。
        - **valueCtx：**valueCtx 继承了一个 匿名Context；一个 valueCtx 中仅有一组 kv 对，通过 WithValue 函数，可以创建层层的 valueCtx，存储 goroutine 间可以共享的变量
- context的4种底层实现都是锁mutex和channel的结合，前者用于修改字段参数，后者用于通信，所以Context 是并发安全的，主要是用于控制多个协程之间的协作、取消操作
- 使用上，先创建一个根节点的 context，之后根据库提供的四个函数创建相应功能的子节点 context，Context形成了⼀种树状结构；
- context在很大程度上利用了channel在close时会通知所有监听它的协程这一特性来实现。**Done()方法返回一个只读的channel，所有相关函数监听此channel。一旦channel关闭，通过channel的“广播机制”，所有监听者都能收到**
- **具体使用场景**：HTTP服务器的request互相传递数据，**Gin 框架中也提供了一个 `gin.Context` 的实现，用于在 Gin 框架中使用 `context.Context`，**gin.Context 的定位是对应于一次 http 请求，贯穿于整条 handlersChain 调用链路的上下文(封装了 **http.Request(包含ctx)**)